{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e5f3e2-5528-432e-9c56-db434508e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'qwiklabs-gcp-03-223e89e2542f'\n",
    "PROJECT = BUCKET\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e365f9f7-7638-49e8-b5d2-eeccbc1d4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '2.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89484ee7-c5c4-4c1f-a4f3-3bb817a7208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12b996f5-0861-4358-b401-d668de24ed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training/validation data ...\n",
      "Training the model ...\n",
      "Model: \"nnlm_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "input (KerasLayer)           (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 124,653,123\n",
      "Trainable params: 10,435\n",
      "Non-trainable params: 124,642,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "3125/3125 [==============================] - 19s 5ms/step - loss: 0.5271 - accuracy: 0.8030 - val_loss: 0.5036 - val_accuracy: 0.8084\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50362, saving model to /home/jupyter/model_checkpoint\n",
      "Epoch 2/2\n",
      "3125/3125 [==============================] - 17s 5ms/step - loss: 0.5000 - accuracy: 0.8119 - val_loss: 0.4967 - val_accuracy: 0.8110\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50362 to 0.49667, saving model to /home/jupyter/model_checkpoint\n",
      "Exported trained model to text_trained/1645620017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 12:39:33.713369: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "2022-02-23 12:39:33.780721: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-02-23 12:39:35.060194: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_349\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-02-23 12:39:35.135025: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-02-23 12:39:52.011565: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_7353\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-02-23 12:39:54.741266: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-02-23 12:40:11.319052: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/trainer_text_distributed\n",
    "python -m trainer_text_distributed.task \\\n",
    "  --output_dir=text_trained \\\n",
    "  --train_data_path=gs://${BUCKET}/data_text/train.csv \\\n",
    "  --test_data_path=gs://${BUCKET}/data_text/test.csv \\\n",
    "  --epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6abe65cd-7bbc-434a-a982-5db2a279e4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: text_model_220223_124528\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [text_model_220223_124528] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe text_model_220223_124528\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs text_model_220223_124528\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/text_trained_model\n",
    "INPUTDIR=gs://${BUCKET}/data_text/train.csv\n",
    "JOBNAME=text_model_$(date -u +%y%m%d_%H%M%S)\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer_text_distributed.task \\\n",
    "  --package-path=$(pwd)/trainer_text_distributed \\\n",
    "  --job-dir=gs://${BUCKET}/text_trained_model \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=basic-gpu \\\n",
    "  --runtime-version=2.5 \\\n",
    "  --python-version=3.7 \\\n",
    "  -- \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --train_data_path=${INPUTDIR} \\\n",
    "  --test_data_path=gs://${BUCKET}/data_text/test.csv \\\n",
    "  --epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bea6752-c195-4aee-8c2d-7eaf43dd8caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2022-02-23T12:45:32Z'\n",
      "endTime: '2022-02-23T13:13:46Z'\n",
      "etag: IAqL-97LevU=\n",
      "jobId: text_model_220223_124528\n",
      "jobPosition: '0'\n",
      "startTime: '2022-02-23T12:52:42Z'\n",
      "state: SUCCEEDED\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --output_dir=gs://qwiklabs-gcp-03-223e89e2542f/text_trained_model\n",
      "  - --train_data_path=gs://qwiklabs-gcp-03-223e89e2542f/data_text/train.csv\n",
      "  - --test_data_path=gs://qwiklabs-gcp-03-223e89e2542f/data_text/test.csv\n",
      "  - --epochs=50\n",
      "  jobDir: gs://qwiklabs-gcp-03-223e89e2542f/text_trained_model\n",
      "  packageUris:\n",
      "  - gs://qwiklabs-gcp-03-223e89e2542f/text_model_220223_124528/feedf372c5e57128f70a97019b267eaef3d8c67644fb634bb5f2325e07fd9e21/trainer_text_distributed-0.0.0.tar.gz\n",
      "  pythonModule: trainer_text_distributed.task\n",
      "  pythonVersion: '3.7'\n",
      "  region: us-central1\n",
      "  runtimeVersion: '2.5'\n",
      "  scaleTier: BASIC_GPU\n",
      "trainingOutput:\n",
      "  consumedMLUnits: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/text_model_220223_124528?project=qwiklabs-gcp-03-223e89e2542f\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Ftext_model_220223_124528&project=qwiklabs-gcp-03-223e89e2542f\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform jobs describe text_model_220223_124528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94df7b81-a196-42b0-83aa-c8cfc1b5e7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Created ai platform model [projects/qwiklabs-gcp-03-223e89e2542f/models/text_model_distributed].\n",
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......\n",
      "..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"text_model_distributed\"\n",
    "MODEL_VERSION=\"text_ml_on_gcp\"\n",
    "MODEL_LOCATION=$(gsutil ls -ld -- gs://${BUCKET}/text_trained_model/1* | tail -1 | tr -d '[:space:]')\n",
    "gcloud ai-platform models create ${MODEL_NAME}\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} \\\n",
    "    --model=${MODEL_NAME} \\\n",
    "    --origin=${MODEL_LOCATION} \\\n",
    "    --runtime-version=2.5 \\\n",
    "    --python-version=3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99b9a9f5-8c49-4478-8a54-f86c0246fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya29.c.b0AXv0zTPgzTjcx-TqSgHO39dNwG601Ts6KhMnpvK84SVB5TrhXrcMZx42ghu2Ddo7kw80p5tLXMzfZBqjdGe19z_mkzXcuaTIT9UU0LaBLwOwlV3Ci95QXNbKpBLyqRk34iwVB5WE-yNd3NWRH_x_FkjqVH-MKJxcB6Yy0tguixalNEsjtnfYfISXoZsRTgDym_bg0LdhlXs............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "import json\n",
    "\n",
    "MODEL_NAME = \"text_model_distributed\"\n",
    "MODEL_VERSION = \"text_ml_on_gcp\"\n",
    "\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1392eec4-afe4-4460-a513-840d8d3382a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n    \"predictions\": [[0.911958098, 0.0130848847, 0.0749569833]\\n    ]\\n}'\n"
     ]
    }
   ],
   "source": [
    "api = \"https://us-central1-ml.googleapis.com/v1/projects/{}/models/{}/versions/{}:predict\" \\\n",
    "         .format(PROJECT, MODEL_NAME, MODEL_VERSION)\n",
    "headers = {\"Authorization\": \"Bearer \" + token }\n",
    "\n",
    "model_input=\"very bad canned food\"\n",
    "\n",
    "data = {\"instances\": [model_input]}\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776bd3c-04f2-4b91-b0ff-4c0380c78bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
